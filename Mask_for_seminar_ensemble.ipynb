{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# 進度條模組\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#檢測tensorflow gpu是否啟用\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8種類\n",
    "class_names = ['normal' , 'error_ear' , 'error_iron' , 'error_solder' , 'noearing' , 'noiron' , 'NG']\n",
    "\n",
    "# 只挑選5類實驗\n",
    "# class_names = ['normal'  , 'error_iron' , 'error_ear' , 'noiron' , 'noearing']\n",
    "\n",
    "class_names_label = {class_name:i for i,class_name in enumerate(class_names)}\n",
    "print(class_names_label)\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "# IMAGE_SIZE = (70 , 120)\n",
    "IMAGE_SIZE = (140 , 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(image):\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "Val_datagen = ImageDataGenerator(rescale = 1/255\n",
    "                                ,preprocessing_function = to_grayscale)\n",
    "\n",
    "\n",
    "Batch_Size = 8\n",
    "\n",
    "test_generator = Val_datagen.flow_from_directory('E://mask_data//20211224_data//test',#类别子文件夹的上一级文件夹\n",
    "                                    batch_size=Batch_Size,\n",
    "                                    shuffle=True,\n",
    "                                    target_size=IMAGE_SIZE,\n",
    "                                    )\n",
    "\n",
    "print(test_generator.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## B0+B1+B2+B3+B4+B5+B6\n",
    "# model_file = ['Mask_AOI-EfficientNetB0_0119_1_g.h5' , 'Mask_AOI-EfficientNetB1_0119_1_g.h5' , 'Mask_AOI-EfficientNetB2_0119_1_g.h5' , \n",
    "#               'Mask_AOI-EfficientNetB3_0119_1_g.h5' ,'Mask_AOI-EfficientNetB4_0119_1_g.h5' , 'Mask_AOI-EfficientNetB5_0119_1_g.h5' , \n",
    "#               'Mask_AOI-EfficientNetB6_0119_1_g.h5']\n",
    "\n",
    "## B0+B2+B3+B4+B5\n",
    "# model_file = ['Mask_AOI-EfficientNetB1_0119_1_g.h5' , 'Mask_AOI-EfficientNetB2_0119_1_g.h5' , 'Mask_AOI-EfficientNetB3_0119_1_g.h5' , \n",
    "#               'Mask_AOI-EfficientNetB4_0119_1_g.h5' , 'Mask_AOI-EfficientNetB5_0119_1_g.h5']\n",
    "\n",
    "## B0+B2+B3\n",
    "# model_file = ['Mask_AOI-EfficientNetB1_0119_1_g.h5' ,  'Mask_AOI-EfficientNetB2_0119_1_g.h5' , 'Mask_AOI-EfficientNetB3_0119_1_g.h5']\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "# model_file = ['Mask_seminar20220215_240_EfficientNetB0.h5','Mask_seminar20220215_240_EfficientNetB1.h5',\n",
    "#               'Mask_seminar20220215_240_EfficientNetB2.h5','Mask_seminar20220215_240_EfficientNetB3.h5',\n",
    "#              'Mask_seminar20220215_240_EfficientNetB5.h5','Mask_seminar20220215_240_EfficientNetB6.h5',\n",
    "#              'Mask_seminar20220215_240_EfficientNetB7.h5']\n",
    "\n",
    "# model_file = ['Mask_seminar20220215_240_EfficientNetB0.h5','Mask_seminar20220215_240_EfficientNetB1.h5',\n",
    "#               'Mask_seminar20220215_240_EfficientNetB2.h5','Mask_seminar20220215_240_EfficientNetB6.h5',\n",
    "#              'Mask_seminar20220215_240_EfficientNetB7.h5']\n",
    "\n",
    "# model_file = ['Mask_seminar20220215_240_EfficientNetB0.h5','Mask_seminar20220215_240_EfficientNetB2.h5',\n",
    "#               'Mask_seminar20220215_240_EfficientNetB6.h5']\n",
    "\n",
    "# model_file = ['Mask_seminar20220215_240_EfficientNetB0.h5','Mask_seminar20220215_240_EfficientNetB6.h5',\n",
    "#              'Mask_seminar20220215_240_EfficientNetB7.h5']\n",
    "\n",
    "# model_file = ['Mask_seminar20220215_240_EfficientNetB2.h5','Mask_seminar20220215_240_EfficientNetB6.h5',\n",
    "#                'Mask_seminar20220215_240_EfficientNetB7.h5']\n",
    "\n",
    "model_file = ['Mask_seminar20220215_240_EfficientNetB0.h5','Mask_seminar20220215_240_EfficientNetB2.h5',\n",
    "              'Mask_seminar20220215_240_EfficientNetB7.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = '20220208_(70_120)_model_acc_loss_pic_B0-B7//Mask_AOI-EfficientNetB0_0119_1_g.h5'\n",
    "# model = tf.keras.models.load_model(filepath)\n",
    "\n",
    "# predictions = model.predict(test_generator)     \n",
    "# pred_labels = np.argmax(predictions, axis = 1) \n",
    "# pred_labels = np.array(pred_labels,dtype = 'int32')\n",
    "# pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predictions_All = []\n",
    "# for model in model_file:\n",
    "#     model = tf.keras.models.load_model('20220208_(70_120)_model_acc_loss_pic_B0-B7//'+model)\n",
    "#     predictions = model.predict(test_generator)\n",
    "#     pred_labels = np.argmax(predictions, axis = 1) \n",
    "#     pred_labels = np.array(pred_labels,dtype = 'int32')\n",
    "#     y_predictions_All.append(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_predictions_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "\n",
    "# labels = np.array(y_predictions_All)\n",
    "# labels = np.transpose(labels, (1, 0))\n",
    "# labels = scipy.stats.mode(labels, axis=0)[0]\n",
    "# labels = np.squeeze(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = 'E://mask_data//20211224_data//test//'\n",
    "pred_data = list(test_generator.class_indices.keys())\n",
    "print(pred_data)\n",
    "\n",
    "class_names = pred_data\n",
    "\n",
    "\n",
    "fp_count = 0\n",
    "labels = []\n",
    "images = []\n",
    "pred_labels = []\n",
    "y_predictions_All = []\n",
    "file_count = 0\n",
    "for pred_dir_name in pred_data:\n",
    "    pred_file_path = pred_path+pred_dir_name\n",
    "    pred_file_list = os.listdir(pred_file_path)\n",
    "    for file_name in pred_file_list:\n",
    "        file_count = file_count+1\n",
    "        image = cv2.imread(pred_file_path+'/'+file_name)\n",
    "        image = np.array(image)\n",
    "#         image = cv2.resize(image,(120 , 70))\n",
    "        image = cv2.resize(image,(240 , 140))\n",
    "        image = image/255\n",
    "        image = tf.image.rgb_to_grayscale(image)\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "        \n",
    "#         for model in model_file:\n",
    "#             model = tf.keras.models.load_model('20220208_(70_120)_model_acc_loss_pic_B0-B7//'+model)\n",
    "#             predictions = model.predict(test_generator)\n",
    "#             pred_labels = np.argmax(predictions, axis = 1) \n",
    "#             pred_labels = np.array(pred_labels,dtype = 'int32')\n",
    "#             y_predictions_All.append(pred_labels)\n",
    "        images.append(image)\n",
    "        labels.append(pred_data.index(pred_dir_name))\n",
    "        for_pred_labels = utils.to_categorical(labels , nb_classes , dtype = 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images , dtype = 'float32')\n",
    "labels = np.array(labels , dtype = 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle           \n",
    "\n",
    "# test_images, test_labels = shuffle(images, for_pred_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.argmax(test_labels, axis = 1) \n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model in model_file:\n",
    "    model = tf.keras.models.load_model(model)\n",
    "    models.append(model)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    model.evaluate(images, for_pred_labels, batch_size=128)\n",
    "#     model.evaluate(test_images, test_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    predictions = model.predict(images)\n",
    "#     predictions = model.predict(test_images)\n",
    "    pred_labels = np.argmax(predictions, axis = 1) \n",
    "    pred_labels = np.array(pred_labels,dtype = 'int32')\n",
    "    y_predictions_All.append(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predictions_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "ensemble_labels = np.array(y_predictions_All)\n",
    "ensemble_labels = scipy.stats.mode(ensemble_labels, axis=0)[0]\n",
    "ensemble_labels = np.squeeze(ensemble_labels)\n",
    "ensemble_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Oranges):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    title='Mask EfficientNet Ensemble confusion matrix'\n",
    "\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "#     plt.savefig('E://Mask_confusion//Mask-EvolvedB0.jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "confusion_mtx = confusion_matrix(labels, ensemble_labels)\n",
    "plot_confusion_matrix(confusion_mtx, classes = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy : {}\".format(accuracy_score(labels, ensemble_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
