{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# 進度條模組\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#檢測tensorflow gpu是否啟用\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8種類\n",
    "class_names = ['normal' , 'error_ear' , 'error_iron' , 'error_solder' , 'noearing' , 'noiron' , 'NG']\n",
    "\n",
    "# 只挑選5類實驗\n",
    "# class_names = ['normal'  , 'error_iron' , 'error_ear' , 'noiron' , 'noearing']\n",
    "\n",
    "class_names_label = {class_name:i for i,class_name in enumerate(class_names)}\n",
    "print(class_names_label)\n",
    "\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "IMAGE_SIZE = (70 , 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "#     datasets = ['mask/20211224_data/train' , 'mask/20211224_data/validation' , 'mask/20211224_data/test']\n",
    "#     output = []\n",
    "    \n",
    "#     for dataset in datasets:\n",
    "#         images = []\n",
    "#         labels = []\n",
    "        \n",
    "#         print('Loading{}'.format(dataset))\n",
    "        \n",
    "#         for folder in os.listdir(dataset):\n",
    "#             label = class_names_label[folder]\n",
    "            \n",
    "#             for file in (os.listdir(os.path.join(dataset , folder))):\n",
    "                \n",
    "#                 img_path = os.path.join(os.path.join(dataset , folder), file)\n",
    "                \n",
    "#                 image = cv2.imread(img_path)\n",
    "#                 image = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "#                 image = cv2.resize(image , IMAGE_SIZE)\n",
    "                \n",
    "#                 images.append(image)\n",
    "#                 labels.append(label)\n",
    "                \n",
    "#         images = np.array(images , dtype = 'float32')\n",
    "#         labels = np.array(labels , dtype = 'int32')\n",
    "#         labels = utils.to_categorical(labels , nb_classes , dtype = 'int32')\n",
    "#         output.append((images,labels))\n",
    "        \n",
    "#     return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import utils\n",
    "# (train_images, train_labels), (val_images, val_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle           \n",
    "\n",
    "# train_images, train_labels = shuffle(train_images, train_labels, random_state=25)\n",
    "# val_images, val_labels = shuffle(val_images, val_labels, random_state=25)\n",
    "# test_images, test_labels = shuffle(test_images, test_labels, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check how many training and testing example do we have\n",
    "# # check the size of image\n",
    "\n",
    "# n_train = train_labels.shape[0]\n",
    "# n_val = val_labels.shape[0]\n",
    "# n_test = test_labels.shape[0]\n",
    "\n",
    "# print('Number of training example : {}'.format(n_train))\n",
    "# print('Number of validation example : {}'.format(n_val))\n",
    "# print('Number of testing example : {}'.format(n_test))\n",
    "# print('Each image is of size : {}'.format(IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = train_images / 255.0\n",
    "# val_images = val_images / 255.0\n",
    "# test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 灰階專用\n",
    "# train_images = tf.expand_dims(train_images, axis=-1)\n",
    "# val_images = tf.expand_dims(val_images, axis=-1)\n",
    "# test_images = tf.expand_dims(test_images, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_images.shape)\n",
    "# print(val_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(image):\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "Train_datagen = ImageDataGenerator(horizontal_flip=True\n",
    "                             ,rescale = 1/255\n",
    "                            ,width_shift_range = 0.03,\n",
    "                            height_shift_range = 0.02,\n",
    "                            preprocessing_function = to_grayscale)\n",
    "\n",
    "Val_datagen = ImageDataGenerator(rescale = 1/255\n",
    "                                ,preprocessing_function = to_grayscale)\n",
    "\n",
    "\n",
    "Batch_Size = 8\n",
    "\n",
    "\n",
    "train_generator = Train_datagen.flow_from_directory('E://mask_data//20211224_data//train',#类别子文件夹的上一级文件夹\n",
    "                                    batch_size=Batch_Size,\n",
    "                                    shuffle=True,\n",
    "                                    target_size=IMAGE_SIZE,\n",
    "                                    )\n",
    "\n",
    "\n",
    "test_generator = Val_datagen.flow_from_directory('E://mask_data//20211224_data//test',#类别子文件夹的上一级文件夹\n",
    "                                    batch_size=Batch_Size,\n",
    "                                    shuffle=True,\n",
    "                                    target_size=IMAGE_SIZE,\n",
    "                                    )\n",
    "val_generator = Val_datagen.flow_from_directory('E://mask_data//20211224_data//validation',#类别子文件夹的上一级文件夹\n",
    "                                    batch_size=Batch_Size,\n",
    "                                    shuffle=True,\n",
    "                                    target_size=IMAGE_SIZE,\n",
    "                                    )\n",
    "print(train_generator.n)\n",
    "print(val_generator.n)\n",
    "\n",
    "print(test_generator.n)\n",
    "# Train_generator = Train_datagen.flow(train_images,train_labels,batch_size = Batch_Size)\n",
    "# Val_generator = Val_datagen.flow(val_images, val_labels,batch_size=Batch_Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_generator.n % train_generator.batch_size ==0:\n",
    "    step_size_train=train_generator.n//train_generator.batch_size\n",
    "else:\n",
    "    step_size_train=train_generator.n//train_generator.batch_size + 1\n",
    "print(step_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if val_generator.n % val_generator.batch_size ==0:\n",
    "    step_size_val=val_generator.n//val_generator.batch_size\n",
    "else:\n",
    "    step_size_val=val_generator.n//val_generator.batch_size + 1\n",
    "print(step_size_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Flatten ,Dropout ,BatchNormalization\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(105, 175, 3))\n",
    "\n",
    "model = tf.keras.applications.EfficientNetB0(input_tensor=input_layer, include_top=False,weights='imagenet',classifier_activation = 'softmax')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D , GlobalAveragePooling2D , MaxPool2D , Dense ,Dropout\n",
    "\n",
    "last_layer = model.output\n",
    "top_se_squeeze = GlobalAveragePooling2D(name='top_se_squeeze')(last_layer)\n",
    "top_dopout = Dropout(0.2)(top_se_squeeze)\n",
    "top_dense = Dense(nb_classes, activation='softmax', name='softmax')(top_dopout)\n",
    "model = Model(input_layer, top_dense,name = 'EfficientNetB0')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "Adam = tf.keras.optimizers.Adam(learning_rate=0.00001,name='Adam')\n",
    "\n",
    "filepath = 'Mask_seminar_EfficientNetB0.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, verbose=1, mode='max', min_lr=0.0001)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', mode='max', verbose=1, patience=15, min_delta=0.0001)\n",
    "\n",
    "callback_list = [checkpoint , reduce_lr , earlystop]\n",
    "# callback_list = [reduce_lr , earlystop]\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam,metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(train_dataset, epochs=120, verbose=1, validation_data = val_dataset,callbacks = callback_list)\n",
    "with tf.device('/gpu:1'):\n",
    "    history = model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=step_size_train,\n",
    "                    epochs=100, \n",
    "                    verbose=1, \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = step_size_val,\n",
    "                    callbacks = callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'b-', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'], 'r-', label = \"val_acc\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'b-', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'r-', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pridict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '20220208_(70_120)_model_acc_loss_pic_B0-B7//Mask_AOI-EfficientNetB0_0119_1_g.h5'\n",
    "model = tf.keras.models.load_model(filepath)\n",
    "\n",
    "predictions = model.predict(test_generator)     \n",
    "pred_labels = np.argmax(predictions, axis = 1) \n",
    "pred_labels = np.array(pred_labels,dtype = 'int32')\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '20220208_(70_120)_model_acc_loss_pic_B0-B7//Mask_AOI-EfficientNetB0_0119_1_g.h5'\n",
    "\n",
    "model = tf.keras.models.load_model(filepath)\n",
    "\n",
    "results = model.evaluate_generator(test_generator)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_path = 'E://mask_data//20211224_data//test//'\n",
    "pred_data = list(test_generator.class_indices.keys())\n",
    "print(pred_data)\n",
    "\n",
    "class_names = pred_data\n",
    "\n",
    "model = tf.keras.models.load_model(filepath)\n",
    "\n",
    "\n",
    "fp_count = 0\n",
    "labels = []\n",
    "pred_labels = []\n",
    "\n",
    "file_count = 0\n",
    "for pred_dir_name in pred_data:\n",
    "    pred_file_path = pred_path+pred_dir_name\n",
    "    pred_file_list = os.listdir(pred_file_path)\n",
    "    for file_name in pred_file_list:\n",
    "        file_count = file_count+1\n",
    "        image = cv2.imread(pred_file_path+'/'+file_name)\n",
    "        image = np.array(image)\n",
    "        image = cv2.resize(image,(120 , 70))\n",
    "        image = image/255\n",
    "        image = to_grayscale(image)\n",
    "        image = tf.expand_dims(tf.expand_dims(image, axis=-1), axis=0)\n",
    "        with tf.device('/gpu:1'):  \n",
    "            result = np.argmax(model.predict(image), axis = 1)\n",
    "        \n",
    "        \n",
    "        if class_names[result[0]] != pred_dir_name:\n",
    "            print(pred_dir_name, '  result : ',class_names[result[0]],'  file_name: ',file_name)\n",
    "            fp_count = fp_count+1\n",
    "        labels.append(pred_data.index(pred_dir_name))\n",
    "        pred_labels.append(result[0])\n",
    "\n",
    "\n",
    "print('資料總筆數: ',file_count,'錯誤筆數: ',fp_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          cmap=plt.cm.Oranges):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    title='Mask-EfficientNetB7 confusion matrix'\n",
    "\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "#     plt.savefig('E://Mask_confusion//Mask-EvolvedB0.jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "confusion_mtx = confusion_matrix(labels, pred_labels)\n",
    "plot_confusion_matrix(confusion_mtx, classes = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
